{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Objective:\n",
        "\n",
        "Create a one-of-a-kind chatbot that transforms every user message into beautiful, poetic verses using the power of large language models (LLMs) such as Gemini, GPT, Claude, or any other model of your choice. Whether someone types, “I’m feeling happy today,” or shares a deeper sentiment, the chatbot will respond with expressive lines such as: “In fields of joy, your heart does dance, / With sunlight’s glow, your soul’s expanse.”\n",
        "\n",
        "To give your chatbot a poetic soul, you'll apply Prompt Engineering techniques to guide the Gemini model into responding with rhythm and emotion — as if the user is conversing with a thoughtful, lyrical companion. Each message will be crafted to feel personal and profound, bringing a poetic interpretation to everyday thoughts.\n",
        "\n",
        "To make the interaction even more immersive, you’ll implement a typing animation effect, creating the impression of a live poet composing verses in real time."
      ],
      "metadata": {
        "id": "9xvGu3a_xnUG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VI2p0qgTxeSU"
      },
      "outputs": [],
      "source": [
        "#import the libraries\n",
        "import sys\n",
        "import time\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize GPT-2 text generation\n",
        "poetry_bot = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "#define the parameters and how the user given prompt will be affected\n",
        "def poetic_reply(user_message, max_lines=5, max_length=30):\n",
        "    prompt = f\"Transform this into an original poetic verse:\\n{user_message}\"\n",
        "    result = poetry_bot(prompt, max_length=max_length, num_return_sequences=1, temperature=0.9, truncation=True, eos_token_id=50256)\n",
        "    poetic_verse = result[0]['generated_text'].replace(prompt, '').strip()\n",
        "\n",
        "    # Further truncate to lines/verses if needed\n",
        "    lines = poetic_verse.split('\\n')\n",
        "    poetic_verse_truncated = '\\n'.join(lines[:max_lines])\n",
        "    return poetic_verse_truncated\n",
        "\n",
        "#define the typing animation effect\n",
        "def typing_animation(text, delay=0.06):\n",
        "    for char in text:\n",
        "        sys.stdout.write(char)\n",
        "        sys.stdout.flush()\n",
        "        time.sleep(delay)\n",
        "    print()  # for newline after completion\n",
        "\n",
        "# Example Conversation Loop\n",
        "while True:\n",
        "    user_msg = input(\"\\nYou: \")\n",
        "    if user_msg.lower() in ['exit', 'quit']: break\n",
        "    poetic_response = poetic_reply(user_msg)\n",
        "    print(\"\\nPoet bot:\", end=\" \")\n",
        "    typing_animation(poetic_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WlMjw39DxFf",
        "outputId": "945de9c9-c005-405b-af3e-34b289d92a20"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "You: the sun is fading\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Poet bot: away\n",
            "the stars are still at night,\n",
            "the sun is fading away.\n",
            "\n",
            "\n",
            "\n",
            "You: and the moon is waiting\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Poet bot: to see\n",
            "\n",
            "for a hundred thousand years\n",
            "\n",
            "the old days,\n",
            "\n",
            "You: and th enew\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Poet bot: ing, the sky, and the fire,\n",
            "is ever red with his fiery flame;\n",
            "The one who takes the flame, the one who takes the fire,\n",
            "the one who takes the fire, the one who takes the fire;\n",
            "for the flame that will do the deed of its flight\n",
            "\n",
            "You: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qLT80utwHINt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}